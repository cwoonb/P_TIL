{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/ash316/eda-to-prediction-dietanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측에 대한 EDA (DieTanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 때로는 인생에는 잔인한 유머 감각이있어 최악의 시간에 항상 원했던 것을 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Lisa Kleypas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타이타닉 침몰은 역사상 가장 악명 높은 난파선 중 하나입니다. 1912 년 4 월 15 일, 처녀 여행 중에 타이타닉은 빙산과 충돌하여 침몰하여 2224 명의 승객과 승무원 중 1502 명이 사망했습니다. 그래서 DieTanic이라는 이름입니다. 이것은 세상 어느 누구도 잊을 수없는 잊을 수없는 재앙입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타이타닉을 건설하는 데 약 750 만 달러가 걸렸으며 충돌로 인해 바다에서 침몰했습니다. 타이타닉 데이터 셋은 초보자가 데이터 과학 여행을 시작하고 카글 경쟁에 참여할 수있는 매우 훌륭한 데이터 셋입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 노트북의 목표는 예측 모델링 문제에서 워크 플로가 어떻게 진행되는지에 대한 **아이디어를 제공하는 것입니다.** 기능을 확인하는 방법, 새로운 기능 및 기계 학습 개념을 추가하는 방법 초보자도 노트북의 모든 단계를 이해할 수 있도록 노트북을 최대한 기본으로 유지하려고 노력했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "당신이 노트북을 좋아하고 그것이 당신을 도왔다 고 생각한다면 .. 기뻐하십시오. 그것은 나에게 동기를 부여합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 노트북의 내용 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part1 : 탐색 적 데이터 분석 (EDA) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 특징의 분석."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 여러 기능을 고려한 관계 또는 동향 파악"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part2 : Feature Engineering and Data Cleaning:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 몇 가지 기능 추가."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 중복 기능 제거."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 모델링에 적합한 형태로 기능을 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part3 : 예측 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 기본 알고리즘 실행."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 교차 검증."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 조립."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) 중요한 특징 추출."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part1 : 탐색 적 데이터 분석 (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('C:/Users/user/Nano_python/data/Titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age, Cabin 및 Embarked에는 null 값이 있습니다. 나는 그들을 고치려고 노력할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "data['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0],shadow=True)\n",
    "ax[0].set_title('Survived')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('Survived',data=data,ax=ax[1])\n",
    "ax[1].set_title('Survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사고로 살아남은 승객은 많지 않은 것이 분명합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 세트에 탑승 한 891 명의 승객 중 약 350 명만이 생존했습니다. 즉 전체 훈련 세트 중**38.4 %**만이 충돌에서 살아 남았습니다. 우리는 데이터에서 더 나은 통찰력을 얻고 더 많은 승객이 생존하지 못한 승객을 파악하기 위해 더 많은 정보를 조사해야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 세트의 다른 기능을 사용하여 생존율을 확인하려고합니다. 특징 중 일부는 성별, 항만, 나이 등입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 다양한 유형의 기능을 이해하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기능의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주 기능 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "범주 형 변수는 둘 이상의 범주가있는 변수이며 해당 기능의 각 값을 범주별로 분류 할 수 있습니다. 예를 들어 성별은 두 가지 범주 (남성과 여성)를 갖는 범주 형 변수입니다. 이제 이러한 변수를 정렬하거나 정렬 할 수 없습니다. 또한 **명목 변수라고도합니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 세트의 범주 적 특징 : 성별, 당황."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서수 특징 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서수 변수는 범주 형 값과 비슷하지만 그 차이점은 값 사이의 상대 순서 또는 정렬이 가능하다는 것입니다. 예를 들어, \n",
    "**Tall, Medium, Short** 값을 가진 **Height**와 같은 기능이 있으면 Height는 순서 변수입니다. 여기서 변수에 상대적인 정렬을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 세트의 서수 특징 : PClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지속적인 특징 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지형지 물 열의 두 지점 사이 또는 최소값 또는 최대 값 사이의 값을 사용할 수있는 경우 지형지 물은 연속적이라고합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 세트의 지속적인 특징 : 나이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 세트의 지속적인 특징 : 나이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성별 ㅡ> 범주 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Sex','Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "data[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Survived VS Sex')\n",
    "sns.countplot('Sex',hue='Survived',data=data,ax=ax[1])\n",
    "ax[1].set_title('Sex:survived vs Dead')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것은 흥미로워 보인다. 배에있는 남자의 수는 여자의 수보다 훨씬 많다. 여전히 여성 수는 남성 수의 거의 두 배입니다. 선박의 **여성의 생존율은 약 75 % 인 반면 남성의 생존율은 약 18-19 %입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것은 모델링에 **매우 중요한** 기능인 것 같습니다. 하지만 최고입니까? 다른 기능을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pclass ㅡ> 서수 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Pclass,data.Survived,margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "data['Pclass'].value_counts(). plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'],ax=ax[0])\n",
    "ax[0].set_title('Number of Passengers By Pclass')\n",
    "ax[0].set_ylabel('count')\n",
    "sns.countplot('Pclass', hue='Survived', data=data, ax=ax[1])\n",
    "ax[1].set_title('Pclass:Survives vs Dead')\n",
    "plt.show()                                                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사람들은 **돈이 모든 것을 살 수 없다고 말합니다.** 그러나 Pclass 1의 Passenegers of Pclass 1은 구조하는 동안 매우 높은 우선 순위가 부여되었음을 분명히 알 수 있습니다. Pclass 3의 승객 수는 훨씬 많았지 만 여전히 **25 %** 정도의 생존률은 매우 낮습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pclass 1의 경우 생존율은 약 **63 %**이고 Pclass2의 경우 약 **48 %**입니다. 돈과 지위가 중요합니다. 그런 물질주의 세계."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금 더 뛰어 들고 다른 흥미로운 관찰을 확인하십시오. Sex와 Pclass Together로 **생존율**을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data.Sex,data.Survived],data.Pclass,margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Pclass','Survived',hue='Sex',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우 **FactorPlot**을 사용합니다. 범주 형 값을 쉽게 분리 할 수 ​​있기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CrossTab**과 **FactorPlot**을 살펴보면 Pclass1에서 94 명의 **여성 중 3 명만이 사망 한 것처럼 Pclass1에서 여성의 생존율은 약 95-96%**임을 쉽게 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pclass와 상관없이 구출하는 동안 여성에게 최우선 순위가 부여 된 것은 분명합니다. Pclass1의 남성조차도 생존율이 매우 낮습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pclass도 중요한 기능인 것 같습니다. 다른 기능을 분석 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이 ㅡ> 지속적인 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Oldest Passenger was of:',data['Age'].max(),'Years')\n",
    "print('Youngest Passenger was of:',data['Age'].min(),'Years')\n",
    "print('Average Age in the ship:',data['Age'].mean(),'Years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "sns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[0])\n",
    "ax[0].set_title('Plcass and Age vs Survived')\n",
    "ax[0].set_yticks(range(0,110,10))\n",
    "sns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[1])\n",
    "ax[1].set_title('Sex and Age vs Surrvived')\n",
    "ax[1].set_yticks(range(0,110,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 관찰 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Pclass에 따라 어린이 수가 증가하고 10 세 미만의 어린이 (즉, 어린이)의 생존율은 Pclass에 상관없이 양호 해 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Pclass1에서 20-50 세의 Passenegers 생존 가능성은 높고 여성에게는 더 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 남성의 경우 생존 확률은 나이가 증가함에 따라 감소합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞에서 보았 듯이 Age 기능에는 **177** 개의 null 값이 있습니다. 이러한 NaN 값을 대체하기 위해 데이터 집합의 평균 수명을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 문제는 나이가 많은 많은 사람들이 있다는 것입니다. 우리는 평균 연령이 29 세인 4 세 아이를 배정 할 수 없습니다. 승객이 어떤 연령대에 있는지 알 수있는 방법이 있습니까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**빙고 !!!!** <br>\n",
    "**이름** 기능을 확인할 수 있습니다. 이 기능을 살펴보면 이름에 Mr 또는 Mrs와 같은 인사말이 있음을 알 수 있으므로 Mr 및 Mrs의 평균 값을 각 그룹에 할당 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ''컬럼에 무엇이 있습니까 ?? ''---> Feature : p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Initial']=0\n",
    "for i in data:\n",
    "    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #lets extract the Salutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 여기 정규식을 사용하고 있습니다 : [A-Za-z] +). 그것이하는 것은 A-Z 또는 a-z 사이에 있고. (점)이 오는 문자열을 찾는 것입니다. 따라서 이름에서 이니셜을 성공적으로 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Initial,data.Sex).T.style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Checking the Initials with the Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mlle이나 Mme과 같이 맞춤법이 틀린 이니셜이 Miss를 뜻하는 것이므로 Miss와 다른 값으로 대체 할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Initial')['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #lets check the average age by Initials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 나이별 NAN 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning the NaN Values with the Ceil values of the mean ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data.Age.isnull()) & (data.Initial == 'Mr'),'Age'] = 33\n",
    "data.loc[(data.Age.isnull()) & (data.Initial == 'Mrs'),'Age'] = 36\n",
    "data.loc[(data.Age.isnull()) & (data.Initial == 'Master'),'Age'] = 5\n",
    "data.loc[(data.Age.isnull()) & (data.Initial == 'Miss'),'Age'] = 22\n",
    "data.loc[(data.Age.isnull()) & (data.Initial == 'Other'),'Age'] = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Initial')['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  마지막으로 null 값을 확인한다.\n",
    "data.Age.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,10))\n",
    "data[data['Survived']==0].Age.plot.hist(ax = ax[0],bins=20,edgecolor='black',color='red')\n",
    "ax[0].set_title('Survived = 0')\n",
    "x1=list(range(0,85,5))\n",
    "ax[0].set_xticks(x1)\n",
    "data[data['Survived']==1].Age.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\n",
    "ax[1].set_title('Survived= 1')\n",
    "x2=list(range(0,85,5))\n",
    "ax[1].set_xticks(x2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 관찰 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 유아 (5 세 미만)는 다수 (여성과 아동 우선 정책?)로 저장되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 가장 오래된 승객 (80 년)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 최대 사망자 수는 30-40 세의 연령 그룹에있었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Pclass','Survived',col='Initial',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 여성과 아동의 첫 번째 정책은 수업에 관계없이 사실입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 착수-> 범주 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data.Embarked,data.Pclass],[data.Sex,data.Survived],margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 착수 ㅡ> 범주 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data.Embarked,data.Pclass],[data.Sex,data.Survived],margins=True).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 항만에 의한 생존 가능성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chances for Survival by Port Of Embarkation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Embarked','Survived',data=data)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(5,3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "포트 C의 생존 가능성은 0.55 정도이며 S는 가장 낮습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,2,figsize=(20,15))\n",
    "sns.countplot('Embarked',data=data,ax=ax[0,0])\n",
    "ax[0,0].set_title('No. Of Passengers Boarded')\n",
    "sns.countplot('Embarked',hue='Sex',data=data,ax=ax[0,1])\n",
    "ax[0,1].set_title('Male-Female Split for Embarked')\n",
    "sns.countplot('Embarked',hue='Survived',data=data,ax=ax[1,0])\n",
    "ax[1,0].set_title('Embarked vs Survived')\n",
    "sns.countplot('Embarked',hue='Pclass',data=data,ax=ax[1,1])\n",
    "ax[1,1].set_title('Embarked vs Pclass')\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 관찰 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) S에서 탑승 한 최대 패스 네이저. 대다수는 Pclass3에서 온 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) C의 승객들은 많은 사람들이 살아남 았기 때문에 운이 좋았습니다. 그 이유는 모든 Pclass1 및 Pclass2 승객을 구출 한 것일 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Embark S는 대부분의 부자들이 탑승 한 항구에서 바라본다. 여전히 생존 가능성은 낮습니다. Pclass3의 많은 승객이 약 **81** %가 생존하지 못했기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) 포트 Q는 승객의 거의 95 %가 Pclass3 출신이었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Pclass','Survived',hue='Sex',col='Embarked',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 착수 NaN 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Embarked NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "포트 S에서 탑승 한 최대 승객 수를 확인한 결과 NaN을 S로 대체했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.Embarked.isnull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1) Pclass와 상관없이 Pclass1과 Pclass2의 여성의 생존 확률은 거의 1입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 포트 S는 남성과 여성의 생존율이 매우 낮기 때문에 Pclass3 Passenegers에게는 매우 불행한 것으로 보입니다. **(돈 문제)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) 포트 Q는 거의 모두 Pclass 3에서 나온 것처럼 남성에게 무해한 것처럼 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 착수 NaN 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "포트 S에서 탑승 한 최대 승객 수를 확인한 결과 NaN을 S로 대체했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'].fillna('S',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Embarked.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally No NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SibSip ㅡㅡ> Discrete Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 기능은 사람이 혼자인지 또는 가족과 함께 있는지를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형제 자매 = 형제, 자매, 의붓 형제, 이복 누이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배우자 = 남편, 아내"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data.SibSp],data.Survived).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('SibSp','Survived',data=data,ax=ax[0])\n",
    "ax[0].set_title('SibSp vs Survived')\n",
    "sns.factorplot('SibSp','Survived',data=data,ax=ax[1])\n",
    "ax[1].set_title('SibSp vs Survived')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.SibSp,data.Pclass).style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 관찰 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서도 결과는 매우 비슷합니다. 부모와 함께 탑승 한 승객은 생존 가능성이 더 높습니다. 그러나 숫자가 올라 갈수록 줄어 듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생존 가능성은 배에 1-3 명의 부모가있는 누군가에게 좋습니다. 혼자 사는 것이 또한 치명적인 것으로 판명되고 누군가가 배에 4 명 이상의 부모가있을 때 생존 가능성이 줄어 듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 운임-> 연속 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Highest Fare was:',data['Fare'].max())\n",
    "print('Lowest Fare was:',data['Fare'].min())\n",
    "print('Average Fare was:',data['Fare'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest fare is **0.0.** Wow!! a free luxorious ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,3,figsize=(20,8))\n",
    "sns.distplot(data[data['Pclass']==1].Fare,ax=ax[0])\n",
    "ax[0].set_title('Fares in Pclass 1')\n",
    "sns.distplot(data[data['Pclass']==2].Fare,ax=ax[1])\n",
    "ax[1].set_title('Fares in Pclass 2')\n",
    "sns.distplot(data[data['Pclass']==3].Fare,ax=ax[2])\n",
    "ax[2].set_title('Fares in Pclass 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pclass1의 승객 요금에는 큰 분포가있는 것으로 보이며이 분포는 표준이 감소함에 따라 계속 감소합니다. 이것은 또한 연속적이므로 비닝을 사용하여 불연속 값으로 변환 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 기능에 대한 한마디로 관찰 :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**성별** : 여성의 생존 가능성은 남성에 비해 높습니다.\n",
    "\n",
    "**Pclass** : 1 등석 승객이 생존 가능성을 높여주는 경향이 있습니다. Pclass3의 생존율은 매우 낮습니다. \n",
    "              <br>여성의 경우 Pclass1의 생존 가능성은 거의 1이며 Pclass2의 생존 가능성도 높습니다. 돈이 이긴다 !!!.\n",
    "\n",
    "**나이** : 5-10 세 미만의 어린이는 생존 가능성이 높습니다. 15 ~ 35 세 그룹 승객은 많이 사망했습니다.\n",
    "\n",
    "\n",
    "**착수** : 이것은 매우 흥미로운 기능입니다. C에서 생존 할 확률은 Pclass1 승객 대다수가 S에서 일어 났음에도 불구하고 더 나은 것으로 보입니다. <br>Q의 승객은 모두 Pclass3에서 왔습니다.\n",
    "\n",
    "**Parch + SibSp** : 1-2 명의 형제 자매, 배우자 또는 1-3 명의 부모님이 혼자 있거나 대가족과 함께 여행하는 것보다 확률이 더 높습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기능 간의 상관"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(10,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 히트 맵 해석\n",
    "가장 먼저 알아 두어야 할 것은 알파벳이나 문자열을 서로 연관시킬 수 없다는 것이 명백하기 때문에 숫자 기능 만 비교한다는 것입니다. 음모를 이해하기 전에 정확히 상관 관계가 무엇인지 살펴 보겠습니다.\n",
    "\n",
    "**긍정적 상관 관계** : 기능**A가 증가하면 기능 B가 증가하면 양의 상관 관계가 있습니다.** 값 1은 완벽한 양의 상관 관계를 의미합니다.\n",
    "\n",
    "**음의 상관 관계 **: 피처 A의 증가가 피처 B의 감소로 이어지면, 그것들은 음의 상관 관계가 있습니다. 값 -1은 완벽한 음의 상관 관계를 의미합니다.\n",
    "\n",
    "이제 두 기능이 서로 완벽하게 상호 연관되어 있다고 말하면 한 기능이 증가하면 다른 기능도 증가합니다. 이는 두 기능 모두 매우 유사한 정보를 포함하고 있으며 정보의 차이가 거의 없거나 전혀 없음을 의미합니다. 둘 다 거의 동일한 정보를 포함하기 때문에이를 다중 선형성이라고합니다.\n",
    "\n",
    "따라서 둘 중 하나가 중복되므로 두 가지를 모두 사용해야한다고 생각하십니까? 모델을 만들거나 훈련시키는 동안 훈련 시간과 많은 이점을 줄이면서 중복 기능을 제거해야합니다.\n",
    "\n",
    "위의 히트 맵에서 기능이 서로 관련이 없음을 알 수 있습니다. 가장 높은 **상관 관계는 SibSp와 Parch 즉 0.41입니다.** 모든 기능을 계속 수행 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2 : 기능 엔지니어링 및 데이터 정리\n",
    "이제 기능 엔지니어링이란 무엇입니까?\n",
    "\n",
    "기능이있는 데이터 세트가 제공 될 때마다 모든 기능이 중요하지는 않습니다. 제거해야 할 중복 기능이 많이있을 수 있습니다. 또한 다른 지형지 물에서 정보를 관찰하거나 추출하여 새로운 지형지 물을 얻거나 추가 할 수 있습니다.\n",
    "\n",
    "예를 들어 이름 기능을 사용하여 초기 기능을 얻는 것이 있습니다. 새로운 기능을 사용할 수 있는지 확인하고 몇 가지 기능을 제거하십시오. 또한 기존 관련 기능을 예측 모델링에 적합한 형식으로 변환합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age_band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 연령 기능 관련 문제 :\n",
    "앞서 언급 한 것처럼 Age는 연속적인 기능이므로 Machine Learning Models에서 Continous Variables에 문제가 있습니다.\n",
    "\n",
    "**Eg** : 성별을 기준으로 스포츠 인을 그룹화하거나 정리할 경우 남성과 여성별로 쉽게 분리 할 수 ​​있습니다.\n",
    "\n",
    "이제 나이별로 그룹화하면 어떻게 하시겠습니까? 30 명의 사람이있는 경우 30 세의 나이 값이있을 수 있습니다. 이제 문제가 있습니다.\n",
    "\n",
    "비닝 또는 정규화를 통해 이러한 연속 값을 범주 형 값으로 변환해야합니다. 비닝을 사용합니다. 즉, 연령 범위를 단일 빈으로 그룹화하거나 단일 값을 할당합니다.\n",
    "\n",
    "자 승객의 최대 연령은 80 세입니다. 따라서 0-80에서 5 빈으로 범위를 나눕니다. 따라서 80 / 5 = 16입니다. 16의 쓰레기통."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_band']=0\n",
    "data.loc[data['Age']<=16,'Age_band']=0\n",
    "data.loc[(data['Age']>16)&(data['Age']<=32),'Age_band']=1\n",
    "data.loc[(data['Age']>32)&(data['Age']<=48),'Age_band']=2\n",
    "data.loc[(data['Age']>48)&(data['Age']<=64),'Age_band']=3\n",
    "data.loc[data['Age']>64,'Age_band']=4\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age_band'].value_counts().to_frame().style.background_gradient(cmap='summer')#checking the number of passenegers in each band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Age_band','Survived',data=data,col='Pclass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pclass와 상관없이 나이가 증가함에 따라 생존율이 감소한다는 사실은 사실입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가족 구성원 수 와  혼자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 \"Family_size\"및 \"Alone\"이라는 새 기능을 생성하고 분석 할 수 있습니다. 이 기능은 Parch와 SibSp의 요약입니다. 생존율이 승객의 가족 규모와 관련이 있는지 확인할 수 있도록 결합 된 데이터를 제공합니다. 혼자 승객인지 여부를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Family_Size']=0\n",
    "data['Family_Size']=data['Parch']+data['SibSp']#family size\n",
    "data['Alone']=0\n",
    "data.loc[data.Family_Size==0,'Alone']=1#Alone\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(18,6))\n",
    "sns.factorplot('Family_Size','Survived',data=data,ax=ax[0])\n",
    "ax[0].set_title('Family_Size vs Survived')\n",
    "sns.factorplot('Alone','Survived',data=data,ax=ax[1])\n",
    "ax[1].set_title('Alone vs Survived')\n",
    "plt.close(2)\n",
    "plt.close(3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Family_Size = 0은 패스 네 거가 혼자임을 의미합니다. \n",
    "분명히, 당신이 혼자이거나 family_size = 0이면, 생존 가능성은 매우 낮습니다. 가족 수> 4 인 경우 기회도 줄어 듭니다. 이것은 또한 모델에 중요한 기능으로 보입니다. 이것을 자세히 살펴 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Alone','Survived',data=data,hue='Sex',col='Pclass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혼자있는 여성의 가능성이 가족보다 높은 Pclass3을 제외하고는 성별이나 Pclass에 관계없이 혼자있는 것이 해로운 것으로 보입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요금 _ 범위\n",
    "\n",
    "운임 역시 지속적인 특징이므로이를 서수 값으로 변환해야합니다. 이를 위해 **pandas.qcut**을 사용합니다.\n",
    "\n",
    "따라서 **qcut**은 우리가 통과 한 빈의 수에 따라 값을 나누거나 정렬합니다. 따라서 5 개의 구간을 전달하면 5 개의 구간 또는 값 범위에 동일한 간격으로 값이 정렬됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Fare_Range']=pd.qcut(data['Fare'],4)\n",
    "data.groupby(['Fare_Range'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 논의한 바와 같이, **fare_range가 증가함에 따라 생존 가능성이 증가한다는 것을 분명히 알 수 있습니다.**\n",
    "\n",
    "이제 Fare_Range 값을 그대로 전달할 수 없습니다. **Age_Band**에서와 마찬가지로 싱글 톤 값으로 변환해야합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare_cat']=0\n",
    "data.loc[data['Fare']<=7.91,'Fare_cat']=0\n",
    "data.loc[(data['Fare']>7.91)&(data['Fare']<=14.454),'Fare_cat']=1\n",
    "data.loc[(data['Fare']>14.454)&(data['Fare']<=31),'Fare_cat']=2\n",
    "data.loc[(data['Fare']>31)&(data['Fare']<=513),'Fare_cat']=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot('Fare_cat','Survived',data=data,hue='Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare_cat이 증가함에 따라 생존 확률이 증가합니다. 이 기능은 섹스와 함께 모델링하는 동안 중요한 기능이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문자열 값을 숫자로 변환\n",
    "\n",
    "문자열을 기계 학습 모델로 전달할 수 없으므로 성 (Lake) 성별, 시작 (Ebarked) 등의 기능을 숫자 값으로 변환해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sex'].replace(['male','female'],[0,1],inplace=True)\n",
    "data['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\n",
    "data['Initial'].replace(['Mr','Mrs','Miss','Master','Other'],[0,1,2,3,4],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불필요한 기능 삭제\n",
    "**이름->** 범주 기능으로 변환 할 수 없으므로 이름 기능이 필요하지 않습니다.\n",
    "\n",
    "**Age->** Age_band 기능이 있으므로이 기능이 필요하지 않습니다.\n",
    "\n",
    "**티켓->** 분류 할 수없는 임의의 문자열입니다.\n",
    "\n",
    "**운임->** Fare_cat 기능이 있으므로 필요하지 않습니다.\n",
    "\n",
    "**캐빈->** 많은 NaN 값과 많은 승객에게 여러 캐빈이 있습니다. 따라서 이것은 쓸모없는 기능입니다.\n",
    "\n",
    "**Fare_Range->** fare_cat 기능이 있습니다.\n",
    "\n",
    "**PassengerId->** 분류 할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1,inplace=True)\n",
    "sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(18,15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 상관 관계 플롯에서 긍정적으로 관련된 기능을 볼 수 있습니다. 그들 중 일부는 SibSp 및 가족 Family_Size 및 Parch 및 Family_Size이며 Alone 및 Family_Size와 같은 부정적인 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3 : 예측 모델링\n",
    "우리는 EDA 부분에서 통찰력을 얻었습니다. 그러나이를 통해 승객의 생존 여부를 정확하게 예측하거나 알 수 없습니다. 이제 우리는 승객이 훌륭한 분류 알고리즘을 사용할지 여부를 예측할 것입니다. 다음은 모델을 만드는 데 사용할 알고리즘입니다.\n",
    "\n",
    "1) 로지스틱 회귀\n",
    "\n",
    "2) 벡터 기계 지원 (선형 및 방사형)\n",
    "\n",
    "3) 임의의 숲\n",
    "\n",
    "4) K-가장 가까운 이웃\n",
    "\n",
    "5) 순진한 베이 즈\n",
    "\n",
    "6) 의사 결정 트리\n",
    "\n",
    "7) 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required ML packages\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(data,test_size=0.3,random_state=0,stratify=data['Survived'])\n",
    "train_X=train[train.columns[1:]]\n",
    "train_Y=train[train.columns[:1]]\n",
    "test_X=test[test.columns[1:]]\n",
    "test_Y=test[test.columns[:1]]\n",
    "X=data[data.columns[1:]]\n",
    "Y=data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 방사형 지원 벡터 머신 (rbf-SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=svm.SVC(kernel='rbf',C=1,gamma=0.1)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction1=model.predict(test_X)\n",
    "print('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction1,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 지원 벡터 머신 (선형 -SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=svm.SVC(kernel='linear',C=0.1,gamma=0.1)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction2=model.predict(test_X)\n",
    "print('Accuracy for linear SVM is',metrics.accuracy_score(prediction2,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction3=model.predict(test_X)\n",
    "print('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction3,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의사 결정 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DecisionTreeClassifier()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction4=model.predict(test_X)\n",
    "print('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction4,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K- 가까운 이웃 (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KNeighborsClassifier() \n",
    "model.fit(train_X,train_Y)\n",
    "prediction5=model.predict(test_X)\n",
    "print('The accuracy of the KNN is',metrics.accuracy_score(prediction5,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 n_neighbours 속성의 값을 변경하면 KNN 모델의 정확도가 변경됩니다. **기본값은 5**입니다. **n_neighbours**의 다양한 값에 대한 정확도를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_index=list(range(1,11))\n",
    "a=pd.Series()\n",
    "x=[0,1,2,3,4,5,6,7,8,9,10]\n",
    "for i in list(range(1,11)):\n",
    "    model=KNeighborsClassifier(n_neighbors=i) \n",
    "    model.fit(train_X,train_Y)\n",
    "    prediction=model.predict(test_X)\n",
    "    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_Y)))\n",
    "plt.plot(a_index, a)\n",
    "plt.xticks(x)\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(12,6)\n",
    "plt.show()\n",
    "print('Accuracies for different values of n are:',a.values,'with the max value as ',a.values.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가우스 나이브 베이 즈\n",
    "Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GaussianNB()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction6=model.predict(test_X)\n",
    "print('The accuracy of the NaiveBayes is',metrics.accuracy_score(prediction6,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임의의 숲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction7=model.predict(test_X)\n",
    "print('The accuracy of the Random Forests is',metrics.accuracy_score(prediction7,test_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 정확성이 분류기의 견고성을 결정하는 유일한 요인은 아닙니다. 분류 기가 훈련 데이터를 통해 훈련되고 테스트 데이터를 통해 테스트되고 90 %의 정확도를 얻습니다.\n",
    "\n",
    "이제 이것은 분류기에 매우 좋은 정확도 인 것 같습니다. 그러나 모든 새로운 테스트 세트에 대해 90 %가 될 것임을 확인할 수 있습니까 ??. 답은 아니오입니다. 분류자가 어떤 훈련을 할 것인지를 결정할 수 없기 때문입니다. 교육 및 테스트 데이터가 변경되면 정확도도 변경됩니다. 증가 또는 감소 할 수 있습니다. 이것을 모델 분산이라고합니다.\n",
    "\n",
    "이를 극복하고 일반화 된 모델을 얻기 위해 교차 검증을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 검증\n",
    "여러 번 데이터가 불균형합니다. 즉, class1 인스턴스는 많지만 다른 클래스 인스턴스는 적을 수 있습니다. 따라서 데이터 세트의 모든 인스턴스에서 알고리즘을 학습하고 테스트해야합니다. 그런 다음 데이터 세트에 대해 언급 된 모든 정확도의 평균을 취할 수 있습니다.\n",
    "\n",
    "1) K-Fold Cross Validation은 먼저 데이터 집합을 k-subset으로 나누어 작동합니다.\n",
    "\n",
    "2) 데이터 세트를 (k = 5) 부분으로 나눕니다. 테스트를 위해 1 개의 부품을 예약하고 4 개의 부품에 대해 알고리즘을 훈련시킵니다.\n",
    "\n",
    "3) 우리는 각 반복에서 테스트 부분을 변경하고 다른 부분에 대해 알고리즘을 훈련함으로써 프로세스를 계속합니다. 그런 다음 정확도와 오류를 평균하여 알고리즘의 평균 정확도를 얻습니다.\n",
    "\n",
    "이것을 K-Fold Cross Validation이라고합니다.\n",
    "\n",
    "4) 알고리즘은 일부 학습 데이터의 데이터 세트에 적합하지 않을 수 있으며 때로는 다른 학습 세트의 데이터에 적합 할 수도 있습니다. 따라서 교차 검증을 통해 일반화 된 모델을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold #for K-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score #score evaluation\n",
    "from sklearn.model_selection import cross_val_predict #prediction\n",
    "kfold = KFold(n_splits=10, random_state=22) # k=10, split the data into 10 equal parts\n",
    "xyz=[]\n",
    "accuracy=[]\n",
    "std=[]\n",
    "classifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\n",
    "models=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(n_estimators=100)]\n",
    "for i in models:\n",
    "    model = i\n",
    "    cv_result = cross_val_score(model,X,Y, cv = kfold,scoring = \"accuracy\")\n",
    "    cv_result=cv_result\n",
    "    xyz.append(cv_result.mean())\n",
    "    std.append(cv_result.std())\n",
    "    accuracy.append(cv_result)\n",
    "new_models_dataframe2=pd.DataFrame({'CV Mean':xyz,'Std':std},index=classifiers)       \n",
    "new_models_dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,6))\n",
    "box=pd.DataFrame(accuracy,index=[classifiers])\n",
    "box.T.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_models_dataframe2['CV Mean'].plot.barh(width=0.8)\n",
    "plt.title('Average CV Mean Accuracy')\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(8,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불균형으로 인해 분류 정확도가 잘못 될 수 있습니다. 모델이 어디에서 잘못되었는지 또는 모델이 잘못 예측 한 클래스를 보여주는 혼란 매트릭스를 사용하여 요약 된 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 혼란 매트릭스\n",
    "분류기에 의해 작성된 정확하고 잘못된 분류의 수를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(3,3,figsize=(12,10))\n",
    "y_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,0],annot=True,fmt='2.0f')\n",
    "ax[0,0].set_title('Matrix for rbf-SVM')\n",
    "y_pred = cross_val_predict(svm.SVC(kernel='linear'),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,1],annot=True,fmt='2.0f')\n",
    "ax[0,1].set_title('Matrix for Linear-SVM')\n",
    "y_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,2],annot=True,fmt='2.0f')\n",
    "ax[0,2].set_title('Matrix for KNN')\n",
    "y_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,0],annot=True,fmt='2.0f')\n",
    "ax[1,0].set_title('Matrix for Random-Forests')\n",
    "y_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,1],annot=True,fmt='2.0f')\n",
    "ax[1,1].set_title('Matrix for Logistic Regression')\n",
    "y_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,2],annot=True,fmt='2.0f')\n",
    "ax[1,2].set_title('Matrix for Decision Tree')\n",
    "y_pred = cross_val_predict(GaussianNB(),X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,y_pred),ax=ax[2,0],annot=True,fmt='2.0f')\n",
    "ax[2,0].set_title('Matrix for Naive Bayes')\n",
    "plt.subplots_adjust(hspace=0.2,wspace=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**혼동 행렬 해석**\n",
    "왼쪽 대각선은 각 클래스에 대한 올바른 예측 수를 나타내고 오른쪽 대각선은 잘못된 예측 수를 나타냅니다. rbf-SVM의 첫 번째 줄거리를 고려해 보겠습니다.\n",
    "\n",
    "1) 아니오. 정확한 예측값은 **491 (죽음의 경우) + 247 (생존 한 경우)이며 평균 CV 정확도는 (491 + 247) / 891 = 82.8 %입니다.**\n",
    "\n",
    "2) **오류->** 잘못 분류 된 58 명은 생존 한 것으로, 95 명은 사망 한 것으로 생존했다. 따라서 살아남은 상태에서 죽은 것을 예측함으로써 더 많은 실수를 저질렀습니다.\n",
    "\n",
    "모든 행렬을 살펴보면 rbf-SVM은 죽은 승객을 정확하게 예측할 가능성이 높지만 NaiveBayes는 생존 한 승객을 정확하게 예측할 가능성이 높다고 말할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "C=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "gamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "kernel=['rbf','linear']\n",
    "hyper={'kernel':kernel,'C':C,'gamma':gamma}\n",
    "gd=GridSearchCV(estimator=svm.SVC(),param_grid=hyper,verbose=True)\n",
    "gd.fit(X,Y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests\n",
    "임의의 숲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=range(100,1000,100)\n",
    "hyper={'n_estimators':n_estimators}\n",
    "gd=GridSearchCV(estimator=RandomForestClassifier(random_state=0),param_grid=hyper,verbose=True)\n",
    "gd.fit(X,Y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rbf-Svm의 최고 점수는 **82.82 % (C = 0.05, 감마 = 0.1)**입니다. RandomForest의 경우 n_estimators = 900에서 점수는 **81.8 %입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 조립\n",
    "조립은 모델의 정확도 또는 성능을 높이는 좋은 방법입니다. 간단히 말해서 다양한 단일 모델을 결합하여 하나의 강력한 모델을 만듭니다.\n",
    "\n",
    "전화를 사고 다양한 매개 변수를 기반으로 많은 사람들에게 전화를 요청한다고 가정 해 봅시다. 따라서 모든 다른 매개 변수를 분석 한 후 단일 제품에 대해 강력한 판단을 내릴 수 있습니다. 모델의 안정성을 향상시키는 Ensembling입니다. 다음과 같은 방법으로 조립할 수 있습니다.\n",
    "\n",
    "1) 투표 분류기\n",
    "\n",
    "2) 바지\n",
    "\n",
    "3) 부스팅."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**투표 분류기**\n",
    "여러 다른 간단한 기계 학습 모델의 예측을 결합하는 가장 간단한 방법입니다. 모든 하위 모델의 예측을 기반으로 평균 예측 결과를 제공합니다. 하위 모델 또는 기본 모델은 모두 다른 유형입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "ensemble_lin_rbf=VotingClassifier(estimators=[('KNN',KNeighborsClassifier(n_neighbors=10)),\n",
    "                                              ('RBF',svm.SVC(probability=True,kernel='rbf',C=0.5,gamma=0.1)),\n",
    "                                              ('RFor',RandomForestClassifier(n_estimators=500,random_state=0)),\n",
    "                                              ('LR',LogisticRegression(C=0.05)),\n",
    "                                              ('DT',DecisionTreeClassifier(random_state=0)),\n",
    "                                              ('NB',GaussianNB()),\n",
    "                                              ('svm',svm.SVC(kernel='linear',probability=True))\n",
    "                                             ], \n",
    "                       voting='soft').fit(train_X,train_Y)\n",
    "print('The accuracy for ensembled model is:',ensemble_lin_rbf.score(test_X,test_Y))\n",
    "cross=cross_val_score(ensemble_lin_rbf,X,Y, cv = 10,scoring = \"accuracy\")\n",
    "print('The cross validated score is',cross.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**포장**\n",
    "배깅은 일반적인 앙상블 방법입니다. 데이터 세트의 작은 파티션에 유사한 분류자를 적용한 다음 모든 예측의 평균을 취합니다. 평균화로 인해 분산이 줄어 듭니다. 투표 분류기와 달리 배깅은 유사한 분류자를 사용합니다.\n",
    "\n",
    "**태그가있는 KNN**\n",
    "배깅은 분산이 높은 모델에 가장 적합합니다. 이에 대한 예는 의사 결정 트리 또는 임의 포리스트입니다. 작은 값의 n_neighbours로 작은 값의 n_neighbours로 KNN을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model=BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=3),random_state=0,n_estimators=700)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction=model.predict(test_X)\n",
    "print('The accuracy for bagged KNN is:',metrics.accuracy_score(prediction,test_Y))\n",
    "result=cross_val_score(model,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for bagged KNN is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 재갈 의사 결정 트리(Bagged DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BaggingClassifier(base_estimator=DecisionTreeClassifier(),random_state=0,n_estimators=100)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction=model.predict(test_X)\n",
    "print('The accuracy for bagged Decision Tree is:',metrics.accuracy_score(prediction,test_Y))\n",
    "result=cross_val_score(model,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for bagged Decision Tree is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 부스팅\n",
    "부스팅은 분류기의 순차적 학습을 사용하는 조립 기술입니다. 약한 모델을 단계별로 향상시키는 방법으로 부스트는 다음과 같이 작동합니다.\n",
    "\n",
    "모델은 먼저 전체 데이터 세트에 대해 학습됩니다. 이제 모델이 잘못되었을 때 인스턴스를 얻습니다. 이제 다음 반복에서 학습자는 잘못 예측 된 인스턴스에 더 집중하거나 더 많은 가중치를 부여합니다. 따라서 잘못된 인스턴스를 올바르게 예측하려고 시도합니다. 이제이 반복적 인 프로세스는 계속되고 정확도에 한계에 도달 할 때까지 새로운 분류자가 모델에 추가됩니다.\n",
    "\n",
    "## 에이다 부스트 (Adaptive Boosting)\n",
    "이 경우 약한 학습자 또는 추정자는 Decsion Tree입니다. 그러나 dafault base_estimator를 선택한 알고리즘으로 변경할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.1)\n",
    "result=cross_val_score(ada,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for AdaBoost is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 확률 적 그라디언트 부스팅\n",
    "여기 약한 학습자는 의사 결정 트리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "grad=GradientBoostingClassifier(n_estimators=500,random_state=0,learning_rate=0.1)\n",
    "result=cross_val_score(grad,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for Gradient Boosting is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\n",
    "result=cross_val_score(xgboost,X,Y,cv=10,scoring='accuracy')\n",
    "print('The cross validated score for XGBoost is:',result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 AdaBoost에 대해 가장 높은 정확도를 얻었습니다. Hyper-Parameter Tuning을 사용하여 증가 시키려고합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost를위한 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=list(range(100,1100,100))\n",
    "learn_rate=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "hyper={'n_estimators':n_estimators,'learning_rate':learn_rate}\n",
    "gd=GridSearchCV(estimator=AdaBoostClassifier(),param_grid=hyper,verbose=True)\n",
    "gd.fit(X,Y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 AdaBoost에 대해 가장 높은 정확도를 얻었습니다. Hyper-Parameter Tuning을 사용하여 증가 시키려고합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost를위한 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators=list(range(100,1100,100))\n",
    "learn_rate=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "hyper={'n_estimators':n_estimators,'learning_rate':learn_rate}\n",
    "gd=GridSearchCV(estimator=AdaBoostClassifier(),param_grid=hyper,verbose=True)\n",
    "gd.fit(X,Y)\n",
    "print(gd.best_score_)\n",
    "print(gd.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost로 얻을 수있는 최대 정확도는 n_estimators = 200 및 learning_rate = 0.05 인 경우 83.16 %입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최고의 모델을위한 혼동 매트릭스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.05)\n",
    "result=cross_val_predict(ada,X,Y,cv=10)\n",
    "sns.heatmap(confusion_matrix(Y,result),cmap='winter',annot=True,fmt='2.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기능 중요성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(2,2,figsize=(15,12))\n",
    "model=RandomForestClassifier(n_estimators=500,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,0])\n",
    "ax[0,0].set_title('Feature Importance in Random Forests')\n",
    "model=AdaBoostClassifier(n_estimators=200,learning_rate=0.05,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,1],color='#ddff11')\n",
    "ax[0,1].set_title('Feature Importance in AdaBoost')\n",
    "model=GradientBoostingClassifier(n_estimators=500,learning_rate=0.1,random_state=0)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,0],cmap='RdYlGn_r')\n",
    "ax[1,0].set_title('Feature Importance in Gradient Boosting')\n",
    "model=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\n",
    "model.fit(X,Y)\n",
    "pd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,1],color='#FD0F00')\n",
    "ax[1,1].set_title('Feature Importance in XgBoost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForests, AdaBoost 등과 같은 다양한 분류기의 중요한 기능을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 :\n",
    "1) 일반적인 중요한 기능 중 일부는 Initial, Fare_cat, Pclass, Family_Size입니다.\n",
    "\n",
    "2) 섹스 기능은 중요하지 않은 것으로 보이며, Pclass와 결합 된 섹스가 매우 좋은 차별화 요소를 제공한다는 것을 앞에서 본 것처럼 충격적입니다. 섹스는 RandomForests에서만 중요해 보입니다.\n",
    "\n",
    "그러나 많은 분류기에서 최상위에있는 Initial 기능을 볼 수 있습니다. 우리는 이미 Sex와 Initial 사이의 긍정적 인 상관 관계를 보았으므로 성별을 나타냅니다.\n",
    "\n",
    "3) 유사하게 Pclass 및 Fare_cat은 Alone, Parch 및 SibSp를 가진 승객 및 Family_Size의 상태를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
